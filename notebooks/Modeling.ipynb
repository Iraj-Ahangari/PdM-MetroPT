{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f38345-215f-48fc-b587-afbbc17e7c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, transformer networks is going to be used in time series dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a3048db-525b-45f1-af5a-6fbae13f658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06757203-47e8-4c23-8748-84de1d0666fe",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8dc11f1-d0cf-4297-bc8c-f315d4e9d9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>TP2</th>\n",
       "      <th>TP3</th>\n",
       "      <th>H1</th>\n",
       "      <th>DV_pressure</th>\n",
       "      <th>Reservoirs</th>\n",
       "      <th>Oil_temperature</th>\n",
       "      <th>Flowmeter</th>\n",
       "      <th>Motor_current</th>\n",
       "      <th>COMP</th>\n",
       "      <th>DV_eletric</th>\n",
       "      <th>Towers</th>\n",
       "      <th>MPG</th>\n",
       "      <th>LPS</th>\n",
       "      <th>Pressure_switch</th>\n",
       "      <th>Oil_level</th>\n",
       "      <th>Caudal_impulses</th>\n",
       "      <th>imminent_failure</th>\n",
       "      <th>Failure Component Encoded</th>\n",
       "      <th>Failure Type Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 06:00:00</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>9.758</td>\n",
       "      <td>9.760</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>1.576</td>\n",
       "      <td>63.350</td>\n",
       "      <td>19.049625</td>\n",
       "      <td>3.9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 06:00:01</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>9.760</td>\n",
       "      <td>9.760</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>1.578</td>\n",
       "      <td>63.250</td>\n",
       "      <td>19.049625</td>\n",
       "      <td>4.0275</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 06:00:02</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>9.760</td>\n",
       "      <td>9.760</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>1.578</td>\n",
       "      <td>63.325</td>\n",
       "      <td>19.040281</td>\n",
       "      <td>3.9450</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 06:00:03</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>9.756</td>\n",
       "      <td>9.756</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>1.576</td>\n",
       "      <td>63.200</td>\n",
       "      <td>19.040281</td>\n",
       "      <td>3.9300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 06:00:04</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>9.756</td>\n",
       "      <td>9.756</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>1.578</td>\n",
       "      <td>63.150</td>\n",
       "      <td>19.049625</td>\n",
       "      <td>3.9950</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    TP2    TP3     H1  DV_pressure  Reservoirs  \\\n",
       "0  2022-01-01 06:00:00 -0.012  9.758  9.760       -0.028       1.576   \n",
       "1  2022-01-01 06:00:01 -0.012  9.760  9.760       -0.028       1.578   \n",
       "2  2022-01-01 06:00:02 -0.010  9.760  9.760       -0.028       1.578   \n",
       "3  2022-01-01 06:00:03 -0.012  9.756  9.756       -0.030       1.576   \n",
       "4  2022-01-01 06:00:04 -0.012  9.756  9.756       -0.030       1.578   \n",
       "\n",
       "   Oil_temperature  Flowmeter  Motor_current  COMP  DV_eletric  Towers  MPG  \\\n",
       "0           63.350  19.049625         3.9550     1           0       1    1   \n",
       "1           63.250  19.049625         4.0275     1           0       1    1   \n",
       "2           63.325  19.040281         3.9450     1           0       1    1   \n",
       "3           63.200  19.040281         3.9300     1           0       1    1   \n",
       "4           63.150  19.049625         3.9950     1           0       1    1   \n",
       "\n",
       "   LPS  Pressure_switch  Oil_level  Caudal_impulses  imminent_failure  \\\n",
       "0    0                0          0                0                 0   \n",
       "1    0                0          0                0                 0   \n",
       "2    0                0          0                0                 0   \n",
       "3    0                0          0                0                 0   \n",
       "4    0                0          0                0                 0   \n",
       "\n",
       "   Failure Component Encoded  Failure Type Encoded  \n",
       "0                          3                     1  \n",
       "1                          3                     1  \n",
       "2                          3                     1  \n",
       "3                          3                     1  \n",
       "4                          3                     1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/mnt/e/PdM/DataX/MetroPT/Modified_df.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a5fcc-56e5-442a-9f15-41025b80434e",
   "metadata": {},
   "source": [
    "-\r\n",
    "\r\n",
    "## Data Preparation for Fault Prediction Model\r\n",
    "\r\n",
    "In this section, we prepare our dataset for the fault prediction model. Our goal is to predict `imminent_failure` (a binary indicator) using various sensor data. The process involves selecting the relevant features, normalizing certain columns, and splitting the data into features (X) and the target variable (y).\r\n",
    "\r\n",
    "### Step 1: Selecting Columns\r\n",
    "\r\n",
    "We select the following columns as features (X):\r\n",
    "\r\n",
    "- Sensor Data: `TP2`, `TP3`, `H1`, `DV_pressure`, `Reservoirs`, `Oil_temperature`, `Flowmeter`, `Motor_current`\r\n",
    "- Additional Features: `COMP`, `DV_eletric`, `Towers`, `MPG`, `LPS`, `Pressure_switch`, `Oil_level`, `Caudal_impulses`\r\n",
    "\r\n",
    "The target variable (y) is:\r\n",
    "\r\n",
    "- `imminent_failure`: Indicates the presence of a fault.\r\n",
    "\r\n",
    "### Step 2: Normalizing Sensor Data\r\n",
    "\r\n",
    "To ensure that our model performs well, we normalize the sensor data columns. Normalization is done using `StandardScaler` from the scikit-learn library, which standardizes features by removing the mean and scaling to unit variance.\r\n",
    "\r\n",
    "The following sensor data columns are normalized:\r\n",
    "\r\n",
    "- `TP2`, `TP3`, `H1`, `DV_pressure`, `Reservoirs`, `Oil_temperature`, `Flownd for others or for your future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a8769d1-beb4-4cfa-a35d-accd649010b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1055/2976842653.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['TP2', 'TP3', 'H1', 'DV_pressure', 'Reservoirs', 'Oil_temperature', 'Flowmeter', 'Motor_current']] = scaler.fit_transform(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Selecting columns for X and y\n",
    "X = df[['TP2', 'TP3', 'H1', 'DV_pressure', 'Reservoirs', 'Oil_temperature', 'Flowmeter', 'Motor_current', \n",
    "        'COMP', 'DV_eletric', 'Towers', 'MPG', 'LPS', 'Pressure_switch', 'Oil_level', 'Caudal_impulses']]\n",
    "y = df['imminent_failure']\n",
    "\n",
    "# Normalizing specified columns\n",
    "scaler = StandardScaler()\n",
    "X[['TP2', 'TP3', 'H1', 'DV_pressure', 'Reservoirs', 'Oil_temperature', 'Flowmeter', 'Motor_current']] = scaler.fit_transform(\n",
    "    X[['TP2', 'TP3', 'H1', 'DV_pressure', 'Reservoirs', 'Oil_temperature', 'Flowmeter', 'Motor_current']])\n",
    "\n",
    "# Now X is normalized and ready to be used in the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9dd94e-e5e5-4658-81c4-ba95be5a5a0d",
   "metadata": {},
   "source": [
    "-\r\n",
    "\r\n",
    "## Transformer Model for Fault Prediction\r\n",
    "\r\n",
    "In this section, we build and train a Transformer model to predict `imminent_failure` using our preprocessed dataset. The Transformer model, known for its effectiveness in handling sequential data, is well-suited for time-series sensor data.\r\n",
    "\r\n",
    "### Model Architecture\r\n",
    "\r\n",
    "Our Transformer model consists of the following components:\r\n",
    "\r\n",
    "- **Input Layer**: Takes the preprocessed feature set.\r\n",
    "- **Transformer Encoder Blocks**: Multiple layers of transformer encoders, each including:\r\n",
    "  - Multi-head attention mechanism.\r\n",
    "  - Feed-forward neural network.\r\n",
    "  - Layer normalization and dropout for regularization.\r\n",
    "- **MLP Head**: A series of dense layers for classification.\r\n",
    "- **Output Layer**: A single dense layer with sigmoid activation for binary classification (fault/no fault).\r\n",
    "\r\n",
    "### Configuration and Compilation\r\n",
    "\r\n",
    "The model is configured with the following parameters:\r\n",
    "- Number of heads in multi-head attention.\r\n",
    "- Dimension of the feed-forward network.\r\n",
    "- Number of transformer blocks.\r\n",
    "- Dimensionality of the MLP layers.\r\n",
    "- Dropout rates for regularization.\r\n",
    "\r\n",
    "### Building the Model\r\n",
    "\r\n",
    "The model is built using TensorFlow and Keras p_units, dropout, mlp_dropout)\r\n",
    "```\r\n",
    "\r\n",
    "### Model Summary\r\n",
    "\r\n",
    "A summary of the model is provided to understand its complexity anmeters:\r\n",
    "\r\n",
    "```python\r\n",
    "model.summary()\r\n",
    "```\r\n",
    "\r\n",
    "### Training the Model\r\n",
    "\r\n",
    "The model is trained using the following parameters:\r\n",
    "- Loss function: Binary cross-entropy, suitable for binary classification tasks.\r\n",
    "- Optimizer: Adam, a popular choice for deep learning models.\r\n",
    "- Metrics: Acding the model's design and training process in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe45c9c5-b6ce-4d06-9be1-d4affff00662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7437d9-4eaf-4358-af57-559f2e32b375",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Exception encountered when calling layer 'softmax' (type Softmax).\n\ntuple index out of range\n\nCall arguments received by layer 'softmax' (type Softmax):\n  • inputs=tf.Tensor(shape=(None, 4), dtype=float32)\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m mlp_dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mff_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_transformer_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_dropout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Summary of the model\u001b[39;00m\n\u001b[1;32m     56\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout, mlp_dropout)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Transformer Blocks\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_transformer_blocks):\n\u001b[0;32m---> 26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mff_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# MLP Head\u001b[39;00m\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m LayerNormalization(epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)(x)\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36mtransformer_encoder\u001b[0;34m(inputs, head_size, num_heads, ff_dim, dropout)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransformer_encoder\u001b[39m(inputs, head_size, num_heads, ff_dim, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Normalization and Attention\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     x \u001b[38;5;241m=\u001b[39m LayerNormalization(epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)(inputs)\n\u001b[0;32m----> 9\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mMultiHeadAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m Dropout(dropout)(x)\n\u001b[1;32m     11\u001b[0m     res \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m inputs\n",
      "File \u001b[0;32m~/anaconda3/envs/CM/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/CM/lib/python3.10/site-packages/keras/layers/activation/softmax.py:103\u001b[0m, in \u001b[0;36mSoftmax.call\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexp(\n\u001b[1;32m     99\u001b[0m             inputs\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;241m-\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_logsumexp(inputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    101\u001b[0m         )\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msoftmax(inputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msoftmax(inputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis)\n",
      "\u001b[0;31mIndexError\u001b[0m: Exception encountered when calling layer 'softmax' (type Softmax).\n\ntuple index out of range\n\nCall arguments received by layer 'softmax' (type Softmax):\n  • inputs=tf.Tensor(shape=(None, 4), dtype=float32)\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, LayerNormalization, Dropout, MultiHeadAttention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    # Transformer Blocks\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    # MLP Head\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    for dim in mlp_units:\n",
    "        x = Dense(dim, activation=\"relu\")(x)\n",
    "        x = Dropout(mlp_dropout)(x)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Create and compile model\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Model configuration\n",
    "input_shape = X.shape[1:]  # Shape of input features\n",
    "head_size = 256\n",
    "num_heads = 4\n",
    "ff_dim = 4\n",
    "num_transformer_blocks = 4\n",
    "mlp_units = [128, 64]  # Size of the dense layers of the final classifier\n",
    "dropout = 0.1\n",
    "mlp_dropout = 0.1\n",
    "\n",
    "# Build the model\n",
    "model = build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout, mlp_dropout)\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "# model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63c09a-4fd2-4640-bc4d-c9dacc635cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
